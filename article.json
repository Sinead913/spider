[
{"URL": "https://en.wikipedia.org/wiki/Network_monitoring", "webContent": "\n\t\tFrom Wikipedia, the free encyclopedia\n\t\t\n\t\t\n\t\t\n\t\t\n\t\t\n\t\tJump to navigation\n\t\tJump to search\n\t\tThis article is about monitoring for technical failures. For monitoring in the sense of surveillance, but relying mostly on the same technology, see Computer and network surveillance.\nNetwork monitoring is the use of a system that constantly monitors a computer network for slow or failing components and that notifies the network administrator (via email, SMS or other alarms) in case of outages or other trouble. Network monitoring is part of network management.\n\nContents\n\n1 Details\n2 Network tomography\n3 Route analytics\n4 Various types of protocols\n5 Internet server monitoring\n\n5.1 Servers around the globe\n5.2 Web server monitoring process\n5.3 Notification\n\n\n6 See also\n7 Notes and references\n8 External links\n\n\n\nDetails[edit]\nWhile an intrusion detection system monitors a network threats from the outside, a network monitoring system monitors the network for problems caused by overloaded or crashed servers, network connections or other devices.\nFor example, to determine the status of a web server, monitoring software may periodically send an HTTP request to fetch a page. For email servers, a test message might be sent through SMTP and retrieved by IMAP or POP3.\nCommonly measured metrics are response time, availability and uptime, although both consistency and reliability metrics are starting to gain popularity. The widespread addition of WAN optimization devices is having an adverse effect on most network monitoring tools, especially when it comes to measuring accurate end-to-end delay because they limit round-trip delay time visibility.[1]\nStatus request failures, such as when a connection cannot be established, it times-out, or the document or message cannot be retrieved, usually produce an action from the monitoring system. These actions vary; An alarm may be sent (via SMS, email, etc.) to the resident sysadmin, automatic failover systems may be activated to remove the troubled server from duty until it can be repaired, etc.\nMonitoring the performance of a network uplink is also known as network traffic measurement.\n\nNetwork tomography[edit]\nNetwork tomography is an important area of network measurement, which deals with monitoring the health of various links in a network using end-to-end probes sent by agents located at vantage points in the network/Internet.\n\nRoute analytics[edit]\nRoute analytics is another important area of network measurement. It includes\nthe methods, systems, algorithms and tools to monitor the routing posture of networks. Incorrect routing or routing issues cause undesirable performance degradation or downtime.\n\nVarious types of protocols[edit]\nSite monitoring services can check HTTP pages, HTTPS, SNMP, FTP, SMTP, POP3, IMAP, DNS, SSH, TELNET, SSL, TCP, ICMP, SIP, UDP, Media Streaming and a range of other ports with a variety of check intervals ranging from every four hours to every one minute. Typically, most network monitoring services test your server anywhere between once-per-hour to once-per-minute.\n\nInternet server monitoring[edit]\nSee also: Website monitoring\nMonitoring an internet server means that the server owner always knows if one or all of his services go down. Server monitoring may be internal, i.e. web server software checks its status and notifies the owner if some services go down, and external, i.e. some web server monitoring companies check the services status with a certain frequency. Server monitoring can encompass a check of system metrics, such as CPU usage, memory usage, network performance and disk space. It can also include application monitoring, such as checking the processes of programs such as Apache, MySQL, Nginx, Postgres and others.\nExternal monitoring is more reliable, as it keeps on working when the server completely goes down. Good server monitoring tools also have performance benchmarking, alerting capabilities and the ability to link certain thresholds with automated server jobs, such as provisioning more memory or performing a backup.\n\nServers around the globe[edit]\nNetwork monitoring services usually have a number of servers around the globe - for example in America, Europe, Asia, Australia and other locations. By having multiple servers in different geographic locations, a monitoring service can determine if a Web server is available across different networks worldwide. The more the locations used, the more complete is the picture on network availability.\n\nWeb server monitoring process[edit]\nWhen monitoring a web server for potential problems, an external web monitoring service checks a number of parameters. First of all, it monitors for a proper HTTP return code. By HTTP specifications RFC 2616, any web server returns several HTTP codes. Analysis of the HTTP codes is the fastest way to determine the current status of the monitored web server. Third-party application performance monitoring tools  provide additional web server monitoring, alerting and reporting capabilities.\n\nNotification[edit]\nAs the information brought by web server monitoring services is in most cases urgent and may be of crucial importance, various notification methods may be used: e-mail, land-line and cell phones, messengers, SMS, fax, pagers, etc.\n\nSee also[edit]\nBusiness service management\nComparison of network monitoring systems\nHigh availability\nNetwork Monitoring Interface Card\nNetwork traffic measurement\nNetwork tap\nSystem monitor\nService-level agreement\nNotes and references[edit]\n\n\n^ The impact of WAN Optimization on NetFlow/IPFIX measurements\n\n\nExternal links[edit]\n\n\n\nWikiversity has learning resources about  Network monitoring\n\nNetwork Management at Curlie\nList of Network Monitoring and Management Tools at Stanford University \n\n\n\n\n\n\t\t\n\t\tRetrieved from \"https://en.wikipedia.org/w/index.php?title=Network_monitoring&oldid=929348670\"\n\t\t\n\t\tCategories: Network managementHidden categories: Articles with Curlie linksPages using RFC magic links\n\t\t\n\t\t\n\t"},
{"URL": "https://en.wikipedia.org/wiki/Network_traffic_measurement", "webContent": "\n\t\tFrom Wikipedia, the free encyclopedia\n\t\t\n\t\t\n\t\t\n\t\t\n\t\t\n\t\tJump to navigation\n\t\tJump to search\n\t\tIn computer networks, network traffic measurement is the process of measuring the amount and type of traffic on a particular network. This is especially important with regard to effective bandwidth management.\n\nContents\n\n1 Techniques\n2 Measurement studies\n3 Tools\n\n3.1 Functions and features\n\n\n4 See also\n5 References\n6 External links\n\n\n\nTechniques[edit]\nNetwork performance could be measured using either active or passive techniques. Active techniques (e.g. Iperf) are more intrusive but are arguably more accurate. Passive techniques have less network overhead and hence can run in the background to be used to trigger network management actions.\n\nMeasurement studies[edit]\nA range of studies have been performed from various points on the Internet. The AMS-IX (Amsterdam Internet Exchange) is one of the world's largest Internet exchanges. It produces a constant supply of simple Internet statistics. There are also numerous academic studies that have produced a range of measurement studies[1][2][3] on frame size distributions, TCP/UDP ratios and TCP/IP options.\n\nTools[edit]\nVarious software tools are available to measure network traffic. Some tools measure traffic by sniffing and others use SNMP, WMI or other local agents to measure bandwidth use on individual machines and routers. However, the latter generally do not detect the type of traffic, nor do they work for machines which are not running the necessary agent software, such as rogue machines on the network, or machines for which no compatible agent is available. In the latter case, inline appliances are preferred. These would generally 'sit' between the LAN and the LAN's exit point, generally the WAN or Internet router, and all packets leaving and entering the network would go through them. In most cases the appliance would operate as a bridge on the network so that it is undetectable by users.\nSome tools used for SNMP monitoring are InfoVista[4], Tivoli Netcool/Proviso [5] by IBM, CA Performance Management by CA Technologies[6], TotalView [7] by PathSolutions, and SolarWinds[8].\n\nFunctions and features[edit]\nMeasurement tools generally have these functions and features:\n\nUser interface (web, graphical, console)\nReal-time traffic graphs\nNetwork activity is often reported against pre-configured traffic matching rules to show:\nLocal IP address\nRemote IP address\nPort number or protocol\nLogged in user name\nBandwidth quotas\nSupport for traffic shaping or rate limiting (overlapping with the network traffic control page)\nSupport website blocking and content filtering\nAlarms to notify the administrator of excessive usage (by IP address or in total)\nSee also[edit]\nIP Flow Information Export and NetFlow\nMeasuring network throughput\nNetwork management\nNetwork monitoring\nNetwork scheduler\nNetwork simulation\nPacket sniffer\nPerformance management\nReferences[edit]\n\n\n^ Murray, David; Terry Koziniec (2012). \"The State of Enterprise Network Traffic in 2012\". 18th Asia-Pacific Conference on Communications (APCC 2012)..mw-parser-output cite.citation{font-style:inherit}.mw-parser-output .citation q{quotes:\"\\\"\"\"\\\"\"\"'\"\"'\"}.mw-parser-output .id-lock-free a,.mw-parser-output .citation .cs1-lock-free a{background:url(\"//upload.wikimedia.org/wikipedia/commons/thumb/6/65/Lock-green.svg/9px-Lock-green.svg.png\")no-repeat;background-position:right .1em center}.mw-parser-output .id-lock-limited a,.mw-parser-output .id-lock-registration a,.mw-parser-output .citation .cs1-lock-limited a,.mw-parser-output .citation .cs1-lock-registration a{background:url(\"//upload.wikimedia.org/wikipedia/commons/thumb/d/d6/Lock-gray-alt-2.svg/9px-Lock-gray-alt-2.svg.png\")no-repeat;background-position:right .1em center}.mw-parser-output .id-lock-subscription a,.mw-parser-output .citation .cs1-lock-subscription a{background:url(\"//upload.wikimedia.org/wikipedia/commons/thumb/a/aa/Lock-red-alt-2.svg/9px-Lock-red-alt-2.svg.png\")no-repeat;background-position:right .1em center}.mw-parser-output .cs1-subscription,.mw-parser-output .cs1-registration{color:#555}.mw-parser-output .cs1-subscription span,.mw-parser-output .cs1-registration span{border-bottom:1px dotted;cursor:help}.mw-parser-output .cs1-ws-icon a{background:url(\"//upload.wikimedia.org/wikipedia/commons/thumb/4/4c/Wikisource-logo.svg/12px-Wikisource-logo.svg.png\")no-repeat;background-position:right .1em center}.mw-parser-output code.cs1-code{color:inherit;background:inherit;border:inherit;padding:inherit}.mw-parser-output .cs1-hidden-error{display:none;font-size:100%}.mw-parser-output .cs1-visible-error{font-size:100%}.mw-parser-output .cs1-maint{display:none;color:#33aa33;margin-left:0.3em}.mw-parser-output .cs1-subscription,.mw-parser-output .cs1-registration,.mw-parser-output .cs1-format{font-size:95%}.mw-parser-output .cs1-kern-left,.mw-parser-output .cs1-kern-wl-left{padding-left:0.2em}.mw-parser-output .cs1-kern-right,.mw-parser-output .cs1-kern-wl-right{padding-right:0.2em}\n\n^ Zhang, Min; Maurizio Dusi; Wolfgang John; Changjia Chen (2009). \"Analysis of udp traffic usage on internet backbone links\". In Proceedings of the 2009 Ninth Annual International Symposium on Applications and the Internet.\n\n^ Wolfgang, John; Sven Tafvelin (2007). \"Analysis of internet backbone traffic and header anomalies observed\". ACM Wireless Networks. Proceedings of the 7th ACM SIGCOMM conference on Internet measurement.\n\n^ \"Product Overview\". InfoVista.com. Retrieved 27 September 2018.\n\n^ \"Configuring IBM Tivoli Storage Manager SNMP\". ibm.com. Retrieved 27 September 2018.\n\n^ \"CA Performance Management - 2.8\". docops.ca.com. Retrieved 27 September 2018.\n\n^ \"Selecting The Right Network Troubleshooting Tool Part Three: SNMP\". PathSolutions.com. Retrieved 27 September 2018.\n\n^ \"SNMP Monitoring\". SolarWinds.com. Retrieved 27 September 2018.\n\n\nExternal links[edit]\nAMS-IX Internet Statistics\nNetwork Event Detection With Entropy Measures, Dr. Raimund Eimann, University of Auckland, PDF; 5993\u00a0kB\n\n\n\n\n\n\t\t\n\t\tRetrieved from \"https://en.wikipedia.org/w/index.php?title=Network_traffic_measurement&oldid=933786062\"\n\t\t\n\t\tCategories: Network managementInternet Protocol based network software\n\t\t\n\t\t\n\t"},
{"URL": "https://en.wikipedia.org/wiki/Service-level_agreement", "webContent": "\n\t\tFrom Wikipedia, the free encyclopedia\n\t\t\n\t\t\n\t\t\n\t\t\n\t\t\n\t\tJump to navigation\n\t\tJump to search\n\t\tFor other uses, see SLA (disambiguation).\nA service-level agreement (SLA) is a commitment between a service provider and a client. Particular aspects of the service\u00a0\u2013 quality, availability, responsibilities\u00a0\u2013 are agreed between the service provider and the service user.[1] The most common component of an SLA is that the services should be provided to the customer as agreed upon in the contract. As an example, Internet service providers and telcos will commonly include service level agreements within the terms of their contracts with customers to define the level(s) of service being sold in plain language terms. In this case the SLA will typically have a technical definition in  mean time between failures (MTBF), mean time to repair or mean time to recovery (MTTR); identifying which party is responsible for reporting faults or paying fees; responsibility for various data rates; throughput; jitter; or similar measurable details.\n\nContents\n\n1 Overview\n2 Components\n3 Common metrics\n4 Specific examples\n\n4.1 Backbone Internet providers\n4.2 WSLA\n4.3 Cloud computing\n4.4 Outsourcing\n\n\n5 See also\n6 References\n7 External links\n\n\n\nOverview[edit]\nA service-level agreement is an agreement between two or more parties, where one is the customer and the others are service providers. This can be a legally binding formal or an informal \"contract\" (for example, internal department relationships). The agreement may involve separate organizations, or different teams within one organization. Contracts between the service provider and other third parties are often (incorrectly) called SLAs \u2013 because the level of service has been set by the (principal) customer, there can be no \"agreement\" between third parties; these agreements are simply \"contracts.\" Operational-level agreements or OLAs, however, may be used by internal groups to support SLAs. If some aspect of a service has not been agreed with the customer, it is not an \"SLA\".\nSLAs commonly include many components, from a definition of services to the termination of agreement.[2] To ensure that SLAs are consistently met, these agreements are often designed with specific lines of demarcation and the parties involved are required to meet regularly to create an open forum for communication. Rewards and penalties applying to the provider are often specified.  Most SLAs also leave room for periodic (annual) revisitation to make changes.[3]\nSince late 1980s SLAs have been used by fixed line telecom operators. SLAs are so widely used these days that larger organizations have many different SLAs existing within the company itself. Two different units in an organization script a SLA with one unit being the customer and another being the service provider. This practice helps to maintain the same quality of service amongst different units in the organization and also across multiple locations of the organization. This internal scripting of SLA also helps to compare the quality of service between an in-house department and an external service provider.[4]\nThe output received by the customer as a result of the service provided is the main focus of the service level agreement.\nService level agreements are also defined at different levels:\n\nCustomer-based SLA: An agreement with an individual customer group, covering all the services they use. For example, an SLA between a supplier (IT service provider) and the finance department of a large organization for the services such as finance system, payroll system, billing system, procurement/purchase system, etc.\nService-based SLA: An agreement for all customers using the services being delivered by the service provider. For example:\nA mobile service provider offers a routine service to all the customers and offers certain maintenance as a part of an offer with the universal charging.\nAn email system for the entire organization. There are chances of difficulties arising in this type of SLA as level of the services being offered may vary for different customers (for example, head office staff may use high-speed LAN connections while local offices may have to use a lower speed leased line).\nMultilevel SLA: The SLA is split into the different levels, each addressing different set of customers for the same services, in the same SLA.\nCorporate-level SLA: Covering all the generic service level management (often abbreviated as SLM) issues appropriate to every customer throughout the organization. These issues are likely to be less volatile and so updates (SLA reviews) are less frequently required.\nCustomer-level SLA: covering all SLM issues relevant to the particular customer group, regardless of the services being used.\nService-level SLA: covering all SLM issue relevant to the specific services, in relation to this specific customer group.\nComponents[edit]\nA well defined and typical SLA will contain the following components:[5]\n\nType of service to be provided: It specifies the type of service and any additional details of type of service to be provided. In case of an IP network connectivity, type of service will describe functions such as operation and maintenance of networking equipment, connection bandwidth to be provided, etc.\nThe service's desired performance level, especially its reliability and responsiveness: A reliable service will be the one which suffers minimum disruptions in a specific amount of time and is available at almost all times. A service with good responsiveness will perform the desired action promptly after the customer requests for it.\nMonitoring process and service level reporting: This component describes how the performance levels are supervised and monitored. This process involves gathering of different type of statistics, how frequently this statistics will be collected and how this statistics will be accessed by the customers.\nThe steps for reporting issues with the service: This component will specify the contact details to report the problem to and the order in which details about the issue have to be reported. The contract will also include a time range in which the problem will be looked upon and also till when the issue will be resolved.\nResponse and issue resolution time-frame: Response time-frame is the time period by which the service provider will start the investigation of the issue. Issue resolution time-frame is the time period by which the current service issue will be resolved and fixed.\nRepercussions for service provider not meeting its commitment: If the provider is not able to meet the requirements as stated in SLA then service provider will have to face consequences for the same. These consequences may include customer's right to terminate the contract or ask for a refund for losses incurred by the customer due to failure of service.\nCommon metrics[edit]\nService-level agreements can contain numerous service-performance metrics with corresponding service-level objectives. A common case in IT-service management is a call center or service desk. Metrics commonly agreed to in these cases include:\n\nAbandonment Rate: Percentage of calls abandoned while waiting to be answered.\nASA (Average Speed to Answer): Average time (usually in seconds) it takes for a call to be answered by the service desk.\nTSF (Time Service Factor): Percentage of calls answered within a definite timeframe, e.g., 80% in 20\u00a0seconds.\nFCR (First-Call Resolution): Percentage of incoming calls that can be resolved without the use of a callback or without having the caller call back the helpdesk to finish resolving the case.[6]\nTAT (Turn-Around Time): Time taken to complete a certain task.\nTRT (total resolution time): Total time taken to complete a certain task.\nMTTR (Mean Time To Recover): Time taken to recover after an outage of service.\nUptime is also a common metric, often used for data services such as shared hosting, virtual private servers and dedicated servers. Common agreements include percentage of network uptime, power uptime, number of scheduled maintenance windows, etc.\nMany SLAs track to the Information Technology Infrastructure Library specifications when applied to IT services.\n\nSpecific examples[edit]\nBackbone Internet providers[edit]\nIt is not uncommon for an internet backbone service provider (or network service provider) to explicitly state its own SLA on its website.[7][8][9] The U.S. Telecommunications Act of 1996 does not expressly mandate that companies have SLAs, but it does provide a framework for firms to do so in Sections 251 and 252.[10] Section 252(c)(1) for example (\"Duty to Negotiate\") requires Incumbent local exchange carriers (ILECs) to negotiate in good faith about matters such as resale and access to rights of way.\n\nWSLA[edit]\nA web service level agreement (WSLA) is a standard for service level agreement compliance monitoring of web services. It allows authors to specify the performance metrics associated with a web service application, desired performance targets, and actions that should be performed when performance is not met.\nWSLA Language Specification, version 1.0 was published by IBM on January 28, 2001.\n\nCloud computing[edit]\nThe underlying benefit of cloud computing is shared resources, which is supported by the underlying nature of a shared infrastructure environment. Thus, SLAs span across the cloud and are offered by service providers as a service-based agreement rather than a customer-based agreement. Measuring, monitoring and reporting on cloud performance is based on the end UX or their ability to consume resources. The downside of cloud computing relative to SLAs is the difficulty in determining the root cause of service interruptions due to the complex nature of the environment.\nAs applications are moved from dedicated hardware into the cloud, they need to achieve the same or even more demanding levels of service than classical installations. SLAs for cloud services focus on characteristics of the data center and more recently include characteristics of the network (see carrier cloud) to support end-to-end SLAs.[11]\nAny SLA management strategy considers two well-differentiated phases: negotiating the contract and monitoring its fulfilment in real time. Thus, SLA management encompasses the SLA contract definition: the basic schema with the QoS parameters; SLA negotiation; SLA monitoring; SLA violation detection; and SLA enforcement\u2014according to defined policies.\nThe main point is to build a new layer upon the grid, cloud, or SOA middleware able to create a negotiation mechanism between the providers and consumers of services. An example is the EU\u2013funded Framework 7 research project, SLA@SOI,[12] which is researching aspects of multi-level, multi-provider SLAs within service-oriented infrastructure and cloud computing, while another EU-funded project, VISION Cloud,[13] has provided results with respect to content-oriented SLAs.\nFP7 IRMOS also investigated aspects of translating application-level SLA terms to resource-based attributes in an effort to bridge the gap between client-side expectations and cloud-provider resource-management mechanisms.[14][15] A summary of the results of various research projects in the area of SLAs (ranging from specifications to monitoring, management and enforcement) has been provided by the European Commission.[16]\n\nOutsourcing[edit]\nOutsourcing involves the transfer of responsibility from an organization to a supplier. This new arrangement is managed through a contract that may include one or more SLAs. The contract may involve financial penalties and the right to terminate if any of the SLAs metrics are consistently missed. Setting, tracking and managing SLAs is an important part of the outsourcing relationship management (ORM) discipline. Specific SLAs are typically negotiated up front as part of the outsourcing contract and used as one of the primary tools of outsourcing governance.\nIn software development, specific SLAs can apply to application outsourcing contracts in line with standards in software quality, as well as recommendations provided by neutral organizations like CISQ, which has published numerous papers on the topic (such as Using Software Measurement in SLAs[17]) that are available to the public.\n\nSee also[edit]\nBest-effort delivery\nIT cost transparency\nNetwork monitoring\nOperational-level agreement (OLA)\nService-oriented architecture (SOA)\nService level\nService level objective\nService level requirement\nReferences[edit]\n\n\n^ Kearney, K.T.; Torelli, F. (2011). \"The SLA Model\".  In Wieder, P.; Butler, J.M.; Theilmann, W.; Yahyapour, R. (eds.). Service Level Agreements for Cloud Computing. Springer Science+Business Media, LLC. pp.\u00a043\u201368. ISBN\u00a09781461416142..mw-parser-output cite.citation{font-style:inherit}.mw-parser-output .citation q{quotes:\"\\\"\"\"\\\"\"\"'\"\"'\"}.mw-parser-output .id-lock-free a,.mw-parser-output .citation .cs1-lock-free a{background:url(\"//upload.wikimedia.org/wikipedia/commons/thumb/6/65/Lock-green.svg/9px-Lock-green.svg.png\")no-repeat;background-position:right .1em center}.mw-parser-output .id-lock-limited a,.mw-parser-output .id-lock-registration a,.mw-parser-output .citation .cs1-lock-limited a,.mw-parser-output .citation .cs1-lock-registration a{background:url(\"//upload.wikimedia.org/wikipedia/commons/thumb/d/d6/Lock-gray-alt-2.svg/9px-Lock-gray-alt-2.svg.png\")no-repeat;background-position:right .1em center}.mw-parser-output .id-lock-subscription a,.mw-parser-output .citation .cs1-lock-subscription a{background:url(\"//upload.wikimedia.org/wikipedia/commons/thumb/a/aa/Lock-red-alt-2.svg/9px-Lock-red-alt-2.svg.png\")no-repeat;background-position:right .1em center}.mw-parser-output .cs1-subscription,.mw-parser-output .cs1-registration{color:#555}.mw-parser-output .cs1-subscription span,.mw-parser-output .cs1-registration span{border-bottom:1px dotted;cursor:help}.mw-parser-output .cs1-ws-icon a{background:url(\"//upload.wikimedia.org/wikipedia/commons/thumb/4/4c/Wikisource-logo.svg/12px-Wikisource-logo.svg.png\")no-repeat;background-position:right .1em center}.mw-parser-output code.cs1-code{color:inherit;background:inherit;border:inherit;padding:inherit}.mw-parser-output .cs1-hidden-error{display:none;font-size:100%}.mw-parser-output .cs1-visible-error{font-size:100%}.mw-parser-output .cs1-maint{display:none;color:#33aa33;margin-left:0.3em}.mw-parser-output .cs1-subscription,.mw-parser-output .cs1-registration,.mw-parser-output .cs1-format{font-size:95%}.mw-parser-output .cs1-kern-left,.mw-parser-output .cs1-kern-wl-left{padding-left:0.2em}.mw-parser-output .cs1-kern-right,.mw-parser-output .cs1-kern-wl-right{padding-right:0.2em}\n\n^ \"The Service Level Agreement Zone\". SLA Information Zone. Service Level Agreement Zone. 2015. Retrieved 22 June 2016.\n\n^ Shacklett, M.E. (12 January 2011). \"Five Key Points for Every SLA\". Dell. Archived from the original on 22 December 2012. Retrieved 22 June 2016.\n\n^ Ding, Jianguo (2010). Advances in Network Management. Auerbach Publications. ISBN\u00a0978-1-4200-6455-1.\n\n^ Verma, Dinesh (September 2004). \"Service level agreements on IP networks\" (PDF). 92 (9). Cite journal requires |journal= (help)\n\n^ Desmarais, Mike (2012). \"First Call Resolution\" (PDF).\n\n^ \"Global IP Network SLA\". NTT Communications. Retrieved 22 June 2016.\n\n^ \"Global Latency and Packet Delivery SLA\". Verizon. Retrieved 22 June 2016.\n\n^ \"Business Edition - AT&T U-verse Voice and TV - Terms of Service (TOS) and AT&T Broadband - Service Level Agreement (SLA)\". AT&T. Retrieved 22 June 2016.\n\n^ Wikisource:Telecommunications Act of 1996#SEC. 101. ESTABLISHMENT OF PART II OF TITLE II.\n\n^ Rueda, J.L.; G\u00f3mez, S.G.; Chimento, A.E. (2011). \"The Service Aggregator Use Case Scenario\".  In Wieder, P.; Butler, J.M.; Theilmann, W.; Yahyapour, R. (eds.). Service Level Agreements for Cloud Computing. Springer Science+Business Media, LLC. pp.\u00a0329\u2013342. ISBN\u00a09781461416142.\n\n^ Butler, J.M.; Yahyapour, R.; Theilmann, W. (2011). \"Motivation and Overview\".  In Wieder, P.; Butler, J.M.; Theilmann, W.; Yahyapour, R. (eds.). Service Level Agreements for Cloud Computing. Springer Science+Business Media, LLC. pp.\u00a03\u201312. ISBN\u00a09781461416142.\n\n^ Villari, M.; Tusa, F.; Celesti, A.; Puliafito, A. (2012). \"How to Federate VISION Cloud through SAML/Shibboleth Authentication\".  In De Paoli, F.; Pimentel, E.; Zavattaro, G. (eds.). Service-Oriented and Cloud Computing. Springer-Verlag Berlin Heidelberg. pp.\u00a0259\u2013274. ISBN\u00a09783642334276.\n\n^ Boniface, M.; Nasser, B.; Papay, J.;  et al. (2010). \"Platform-as-a-Service Architecture for Real-Time Quality of Service Management in Clouds\" (PDF). ICIW '10: Proceedings of the 2010 Fifth International Conference on Internet and Web Applications and Services: 155\u2013160. doi:10.1109/ICIW.2010.91. ISBN\u00a0978-1-4244-6728-0.\n\n^ Cuomo, A.; Di Modica, G.; Distefano, S.;  et al. (2013). \"An SLA-based Broker for Cloud Infrastructures\". Journal of Grid Computing. 11 (March 2013): 1\u201325. doi:10.1007/s10723-012-9241-4.\n\n^ Kyriazis, D., ed. (June 2013). \"Cloud Computing Service Level Agreements - Exploitation of Research Results\". European Commission. p.\u00a051. Retrieved 22 June 2016.\n\n^ Curtis, B.; Herron, D.; Subramanyam, J. (July 2015). \"Using Software Measurement in SLAs: Integrating CISQ Size and Structural Quality Measures into Contractual Relationships\" (PDF). CISQ. Retrieved 22 June 2016.\n\n\nExternal links[edit]\nService Level Agreement (SLA) S-Cube Knowledge Model\n\n\n\n\n\n\t\t\n\t\tRetrieved from \"https://en.wikipedia.org/w/index.php?title=Service-level_agreement&oldid=928173132\"\n\t\t\n\t\tCategories: Contract lawOutsourcingIT service managementTerms of serviceServices marketingHidden categories: CS1 errors: missing periodical\n\t\t\n\t\t\n\t"},
{"URL": "https://en.wikipedia.org/wiki/High_availability", "webContent": "\n\t\tFrom Wikipedia, the free encyclopedia\n\t\t\n\t\t\n\t\t\n\t\t\n\t\t\n\t\tJump to navigation\n\t\tJump to search\n\t\t\"Always-on\" redirects here. For the software restriction, see Always-on DRM.\n\n\nsystems with high up-time, a.k.a. \"always on\"\n\nHigh availability (HA) is a characteristic of a system, which aims to ensure an agreed level of operational performance, usually uptime, for a higher than normal period.\nModernization has resulted in an increased reliance on these systems.  For example, hospitals and data centers require high availability of their systems to perform routine daily activities. Availability refers to the ability of the user community to obtain a service or good, access the system, whether to submit new work, update or alter existing work, or collect the results of previous work. If a user cannot access the system, it is \u2013 from the users point of view \u2013 unavailable.[1] Generally, the term downtime is used to refer to periods when a system is unavailable.\n\nContents\n\n1 Principles\n2 Scheduled and unscheduled downtime\n3 Percentage calculation\n\n3.1 \"Nines\"\n\n\n4 Measurement and interpretation\n5 Closely related concepts\n6 Military control systems\n7 System design\n8 Reasons for unavailability\n9 Costs of unavailability\n10 See also\n11 Notes\n12 References\n13 External links\n\n\n\nPrinciples[edit]\nThere are three principles of systems design in reliability engineering which can help achieve high availability.\n\nElimination of single points of failure. This means adding redundancy to the system so that failure of a component does not mean failure of the entire system.\nReliable crossover. In redundant systems, the crossover point itself tends to become a single point of failure.  Reliable systems must provide for reliable crossover.\nDetection of failures as they occur. If the two principles above are observed, then a user may never see a failure \u2013 but the maintenance activity must.\nScheduled and unscheduled downtime[edit]\nThis section does not cite any sources. Please help improve this section by adding citations to reliable sources. Unsourced material may be challenged and removed.Find sources:\u00a0\"High availability\"\u00a0\u2013\u00a0news\u00a0\u00b7 newspapers\u00a0\u00b7 books\u00a0\u00b7 scholar\u00a0\u00b7 JSTOR  (June 2008) (Learn how and when to remove this template message)\nA distinction can be made between scheduled and unscheduled downtime. Typically, scheduled downtime is a result of maintenance that is disruptive to system operation and usually cannot be avoided with a currently installed system design. Scheduled downtime events might include patches to system software that require a reboot or system configuration changes that only take effect upon a reboot. In general, scheduled downtime is usually the result of some logical, management-initiated event. Unscheduled downtime events typically arise from some physical event, such as a hardware or software failure or environmental anomaly. Examples of unscheduled downtime events include power outages, failed CPU or RAM components (or possibly other failed hardware components), an over-temperature related shutdown, logically or physically severed network connections, security breaches, or various application, middleware, and operating system failures.\nIf users can be warned away from scheduled downtimes, then the distinction is useful.  But if the requirement is for true high availability, then downtime is downtime whether or not it is scheduled.\nMany computing sites exclude scheduled downtime from availability calculations, assuming that it has little or no impact upon the computing user community. By doing this, they can claim to have phenomenally high availability, which might give the illusion of continuous availability. Systems that exhibit truly continuous availability are comparatively rare and higher priced, and most have carefully implemented specialty designs that eliminate any single point of failure and allow online hardware, network, operating system, middleware, and application upgrades, patches, and replacements. For certain systems, scheduled downtime does not matter, for example system downtime at an office building after everybody has gone home for the night.\n\nPercentage calculation[edit]\nAvailability is usually expressed as a percentage of uptime in a given year. The following table shows the downtime that will be allowed for a particular percentage of availability, presuming that the system is required to operate continuously. Service level agreements often refer to monthly downtime or availability in order to calculate service credits to match monthly billing cycles. The following table shows the translation from a given availability percentage to the corresponding amount of time a system would be unavailable.\n\n\n\n\nAvailability\u00a0%\n\nDowntime per year[note 1]\n\nDowntime per month\n\nDowntime per week\n\nDowntime per day\n\n\n55.5555555% (\"nine fives\")\n\n162.33 days\n\n13.53 days\n\n74.92 hours\n\n10.67 hours\n\n\n90% (\"one nine\")\n\n36.53 days\n\n73.05 hours\n\n16.80 hours\n\n2.40 hours\n\n\n95% (\"one and a half nines\")\n\n18.26 days\n\n36.53 hours\n\n8.40 hours\n\n1.20 hours\n\n\n97%\n\n10.96 days\n\n21.92 hours\n\n5.04 hours\n\n43.20 minutes\n\n\n98%\n\n7.31 days\n\n14.61 hours\n\n3.36 hours\n\n28.80 minutes\n\n\n99% (\"two nines\")\n\n3.65 days\n\n7.31 hours\n\n1.68 hours\n\n14.40 minutes\n\n\n99.5% (\"two and a half nines\")\n\n1.83 days\n\n3.65 hours\n\n50.40 minutes\n\n7.20 minutes\n\n\n99.8%\n\n17.53 hours\n\n87.66 minutes\n\n20.16 minutes\n\n2.88 minutes\n\n\n99.9% (\"three nines\")\n\n8.77 hours\n\n43.83 minutes\n\n10.08 minutes\n\n1.44 minutes\n\n\n99.95% (\"three and a half nines\")\n\n4.38 hours\n\n21.92 minutes\n\n5.04 minutes\n\n43.20 seconds\n\n\n99.99% (\"four nines\")\n\n52.60 minutes\n\n4.38 minutes\n\n1.01 minutes\n\n8.64 seconds\n\n\n99.995% (\"four and a half nines\")\n\n26.30 minutes\n\n2.19 minutes\n\n30.24 seconds\n\n4.32 seconds\n\n\n99.999% (\"five nines\")\n\n5.26 minutes\n\n26.30 seconds\n\n6.05 seconds\n\n864.00 milliseconds\n\n\n99.9999% (\"six nines\")\n\n31.56 seconds\n\n2.63 seconds\n\n604.80 milliseconds\n\n86.40 milliseconds\n\n\n99.99999% (\"seven nines\")\n\n3.16 seconds\n\n262.98 milliseconds\n\n60.48 milliseconds\n\n8.64 milliseconds\n\n\n99.999999% (\"eight nines\")\n\n315.58 milliseconds\n\n26.30 milliseconds\n\n6.05 milliseconds\n\n864.00 microseconds\n\n\n99.9999999% (\"nine nines\")\n\n31.56 milliseconds\n\n2.63 milliseconds\n\n604.80 microseconds\n\n86.40 microseconds\n\n\nUptime and availability can be used synonymously as long as the items being discussed are kept consistent.  That is, a system can be up, but its services are not available, as in the case of a network outage.  This can also be viewed as a system that is available to be worked on, but its services are not up from a functional perspective (as opposed to software service/process perspective). The perspective is important here - whether the item being discussed is the server hardware, server OS, functional service, software service/process...etc.  Keep the perspective consistent throughout a discussion, then uptime and availability can be used synonymously.\n\n\"Nines\"[edit]\nMain article: Nine (purity)\nPercentages of a particular order of magnitude are sometimes referred to by the number of nines or \"class of nines\" in the digits.  For example, electricity that is delivered without interruptions (blackouts, brownouts or surges) 99.999% of the time would have 5 nines reliability, or class five.[2] In particular, the term is used in connection with mainframes[3][4] or enterprise computing, often as part of a service-level agreement.\nSimilarly, percentages ending in a 5 have conventional names, traditionally the number of nines, then \"five\", so 99.95% is \"three nines five\", abbreviated 3N5.[5][6] This is casually referred to as \"three and a half nines\",[7] but this is incorrect: a 5 is only a factor of 2, while a 9 is a factor of 10, so a 5 is 0.3 nines (per below formula: \n  \n    \n      \n        \n          log\n          \n            10\n          \n        \n        \u2061\n        2\n        \u2248\n        0.3\n      \n    \n    {\\displaystyle \\log _{10}2\\approx 0.3}\n  \n):[note 2] 99.95% availability is 3.3 nines, not 3.5 nines.[8] More simply, going from 99.9% availability to 99.95% availability is a factor of 2 (0.1% to 0.05% unavailability), but going from 99.95% to 99.99% availability is a factor of 5 (0.05% to 0.01% unavailability), over twice as much.[note 3]\nA formulation of the class of 9s  \n  \n    \n      \n        c\n      \n    \n    {\\displaystyle c}\n  \n  based on a system's unavailability \n  \n    \n      \n        x\n      \n    \n    {\\displaystyle x}\n  \n would be\n\n\n  \n    \n      \n        c\n        :=\n        \u230a\n        \u2212\n        \n          log\n          \n            10\n          \n        \n        \u2061\n        x\n        \u230b\n      \n    \n    {\\displaystyle c:=\\lfloor -\\log _{10}x\\rfloor }\n  \n\n(cf. Floor and ceiling functions).\nA similar measurement is sometimes used to describe the purity of substances.\nIn general, the number of nines is not often used by a network engineer when modeling and measuring availability because it is hard to apply in formula. More often, the unavailability expressed as a probability (like 0.00001), or a downtime per year is quoted. Availability specified as a number of nines is often seen in marketing documents.[citation needed] The use of the \"nines\" has been called into question, since it does not appropriately reflect that the impact of unavailability varies with its time of occurrence.[9] For large amounts of 9s, the \"unavailability\" index (measure of downtime rather than uptime) is easier to handle. For example, this is why an \"unavailability\" rather than availability metric is used in hard disk or data link bit error rates.\n\nMeasurement and interpretation[edit]\nAvailability measurement is subject to some degree of interpretation. A system that has been up for 365 days in a non-leap year might have been eclipsed by a network failure that lasted for 9 hours during a peak usage period; the user community will see the system as unavailable, whereas the system administrator will claim 100% uptime. However, given the true definition of availability, the system will be approximately 99.9% available, or three nines (8751 hours of available time out of 8760 hours per non-leap year). Also, systems experiencing performance problems are often deemed partially or entirely unavailable by users, even when the systems are continuing to function. Similarly, unavailability of select application functions might go unnoticed by administrators yet be devastating to users\u00a0\u2014 a true availability measure is holistic.\nAvailability must be measured to be determined, ideally with comprehensive monitoring tools (\"instrumentation\") that are themselves highly available. If there is a lack of instrumentation, systems supporting high volume transaction processing throughout the day and night, such as credit card processing systems or telephone switches, are often inherently better monitored, at least by the users themselves, than systems which experience periodic lulls in demand.\nAn alternative metric is mean time between failures (MTBF).\n\nClosely related concepts[edit]\nRecovery time (or estimated time of repair (ETR), also known as recovery time objective (RTO) is closely related to availability, that is the total time required for a planned outage or the time required to fully recover from an unplanned outage. Another metric is mean time to recovery (MTTR).  Recovery time could be infinite with certain system designs and failures, i.e. full recovery is impossible. One such example is a fire or flood that destroys a data center and its systems when there is no secondary disaster recovery data center.\nAnother related concept is data availability, that is the degree to which databases and other information storage systems faithfully record and report system transactions. Information management often focuses separately on data availability, or Recovery Point Objective, in order to determine acceptable (or actual) data loss with various failure events. Some users can tolerate application service interruptions but cannot tolerate data loss.\nA service level agreement (\"SLA\") formalizes an organization's availability objectives and requirements.\n\nMilitary control systems[edit]\nHigh availability is one of the primary requirements of the control systems in unmanned vehicles and autonomous maritime vessels. If the controlling system becomes unavailable, the Ground Combat Vehicle (GCV) or ASW Continuous Trail Unmanned Vessel (ACTUV) would be lost.\n\nSystem design[edit]\nAdding more components to an overall system design can undermine efforts to achieve high availability because complex systems inherently have more potential failure points and are more difficult to implement correctly. While some analysts would put forth the theory that the most highly available systems adhere to a simple architecture (a single, high quality, multi-purpose physical system with comprehensive internal hardware redundancy), this architecture suffers from the requirement that the entire system must be brought down for patching and operating system upgrades. More advanced system designs allow for systems to be patched and upgraded without compromising service availability (see load balancing and failover).\nHigh availability requires less human intervention to restore operation in complex systems; the reason for this being that the most common cause for outages is human error.[10]\nRedundancy is used to create systems with high levels of availability (e.g. aircraft flight computers). In this case it is required to have high levels of failure detectability and avoidance of common cause failures. Two kinds of redundancy are passive redundancy and active redundancy.\nPassive redundancy is used to achieve high availability by including enough excess capacity in the design to accommodate a performance decline. The simplest example is a boat with two separate engines driving two separate propellers. The boat continues toward its destination despite failure of a single engine or propeller. A more complex example is multiple redundant power generation facilities within a large system involving electric power transmission. Malfunction of single components is not considered to be a failure unless the resulting performance decline exceeds the specification limits for the entire system.\nActive redundancy is used in complex systems to achieve high availability with no performance decline. Multiple items of the same kind are incorporated into a design that includes a method to detect failure and automatically reconfigure the system to bypass failed items using a voting scheme. This is used with complex computing systems that are linked. Internet routing is derived from early work by Birman and Joseph in this area.[11] Active redundancy may introduce more complex failure modes into a system, such as continuous system reconfiguration due to faulty voting logic.\nZero downtime system design means that modeling and simulation indicates mean time between failures significantly exceeds the period of time between planned maintenance, upgrade events, or system lifetime. Zero downtime involves massive redundancy, which is needed for some types of aircraft and for most kinds of communications satellites. Global Positioning System is an example of a zero downtime system.\nFault instrumentation can be used in systems with limited redundancy to achieve high availability. Maintenance actions occur during brief periods of down-time only after a fault indicator activates. Failure is only significant if this occurs during a mission critical period.\nModeling and simulation is used to evaluate the theoretical reliability for large systems. The outcome of this kind of model is used to evaluate different design options. A model of the entire system is created, and the model is stressed by removing components. Redundancy simulation involves the N-x criteria. N represents the total number of components in the system. x is the number of components used to stress the system. N-1 means the model is stressed by evaluating performance with all possible combinations where one component is faulted. N-2 means the model is stressed by evaluating performance with all possible combinations where two component are faulted simultaneously.\n\nReasons for unavailability[edit]\nA survey among academic availability experts in 2010 ranked reasons for unavailability of enterprise IT systems. All reasons refer to not following best practice in each of the following areas (in order of importance):[12]\n\nMonitoring of the relevant components\nRequirements and procurement\nOperations\nAvoidance of network failures\nAvoidance of internal application failures\nAvoidance of external services that fail\nPhysical environment\nNetwork redundancy\nTechnical solution of backup\nProcess solution of backup\nPhysical location\nInfrastructure redundancy\nStorage architecture redundancy\nA book on the factors themselves was published in 2003.[13]\n\nCosts of unavailability[edit]\nIn a 1998 report from IBM Global Services, unavailable systems were estimated to have cost American businesses $4.54 billion in 1996, due to lost productivity and revenues.[14]\n\nSee also[edit]\nDisaster recovery\nFault-tolerance\nReliability, availability and serviceability (computing)\nReliability engineering\nResilience (network)\nUbiquitous computing\nNotes[edit]\n\n\n^ Using 365.25 days per year. For consistency, all times are rounded to two decimal digits.\n\n^ See mathematical coincidences concerning base 2 for details on this approximation.\n\n^ \"Twice as much\" on a logarithmic scale, meaning two factors of 2: \n  \n    \n      \n        \u00d7\n        2\n        \u00d7\n        2\n        <\n        \u00d7\n        5\n      \n    \n    {\\displaystyle \\times 2\\times 2<\\times 5}\n  \n\n\n\nReferences[edit]\n\n\n^ Floyd Piedad, Michael Hawkins (2001). High Availability: Design, Techniques, and Processes. Prentice Hall. ISBN\u00a09780130962881..mw-parser-output cite.citation{font-style:inherit}.mw-parser-output .citation q{quotes:\"\\\"\"\"\\\"\"\"'\"\"'\"}.mw-parser-output .id-lock-free a,.mw-parser-output .citation .cs1-lock-free a{background:url(\"//upload.wikimedia.org/wikipedia/commons/thumb/6/65/Lock-green.svg/9px-Lock-green.svg.png\")no-repeat;background-position:right .1em center}.mw-parser-output .id-lock-limited a,.mw-parser-output .id-lock-registration a,.mw-parser-output .citation .cs1-lock-limited a,.mw-parser-output .citation .cs1-lock-registration a{background:url(\"//upload.wikimedia.org/wikipedia/commons/thumb/d/d6/Lock-gray-alt-2.svg/9px-Lock-gray-alt-2.svg.png\")no-repeat;background-position:right .1em center}.mw-parser-output .id-lock-subscription a,.mw-parser-output .citation .cs1-lock-subscription a{background:url(\"//upload.wikimedia.org/wikipedia/commons/thumb/a/aa/Lock-red-alt-2.svg/9px-Lock-red-alt-2.svg.png\")no-repeat;background-position:right .1em center}.mw-parser-output .cs1-subscription,.mw-parser-output .cs1-registration{color:#555}.mw-parser-output .cs1-subscription span,.mw-parser-output .cs1-registration span{border-bottom:1px dotted;cursor:help}.mw-parser-output .cs1-ws-icon a{background:url(\"//upload.wikimedia.org/wikipedia/commons/thumb/4/4c/Wikisource-logo.svg/12px-Wikisource-logo.svg.png\")no-repeat;background-position:right .1em center}.mw-parser-output code.cs1-code{color:inherit;background:inherit;border:inherit;padding:inherit}.mw-parser-output .cs1-hidden-error{display:none;font-size:100%}.mw-parser-output .cs1-visible-error{font-size:100%}.mw-parser-output .cs1-maint{display:none;color:#33aa33;margin-left:0.3em}.mw-parser-output .cs1-subscription,.mw-parser-output .cs1-registration,.mw-parser-output .cs1-format{font-size:95%}.mw-parser-output .cs1-kern-left,.mw-parser-output .cs1-kern-wl-left{padding-left:0.2em}.mw-parser-output .cs1-kern-right,.mw-parser-output .cs1-kern-wl-right{padding-right:0.2em}\n\n^ Lecture Notes M. Nesterenko, Kent State University\n\n^ Introduction to the new mainframe: Large scale commercial computing Chapter 5 Availability IBM (2006)\n\n^ IBM zEnterprise EC12 Business Value Video at youtube.com\n\n^ Precious metals, Volume 4. Pergamon Press. 1981. p.\u00a0page 262. ISBN\u00a09780080253695.\n\n^ PVD for Microelectronics: Sputter Desposition to Semiconductor Manufacturing. 1998. p.\u00a0387.\n\n^ Murphy, Niall Richard; Beyer, Betsy; Petoff, Jennifer; Jones, Chris (2016). Site Reliability Engineering: How Google Runs Production Systems. p.\u00a038.\n\n^ Josh Deprez (April 23, 2016). \"Nines of Nines\".\n\n^ Evan L. Marcus, The myth of the nines\n\n^ \"Top Seven Considerations for Configuration Management for Virtual and Cloud Infrastructures\". Gartner. October 27, 2010. Retrieved October 13, 2013.\n\n^ RFC\u00a0992\n\n^ Ulrik Franke, Pontus Johnson, Johan K\u00f6nig, Liv Marcks von W\u00fcrtemberg: Availability of enterprise IT systems \u2013 an expert-based Bayesian model, Proc. Fourth International Workshop on Software Quality and Maintainability (WSQM 2010), Madrid, [1]\n\n^ Marcus, Evan; Stern, Hal (2003). Blueprints for high availability (Second ed.). Indianapolis, IN: John Wiley & Sons. ISBN\u00a00-471-43026-9.\n\n^ IBM Global Services, Improving systems availability, IBM Global Services, 1998, [2]\n\n\nExternal links[edit]\nLecture Notes on Enterprise Computing University of T\u00fcbingen\nUptime Calculator (SLA)\n\n\n\n\n\n\t\t\n\t\tRetrieved from \"https://en.wikipedia.org/w/index.php?title=High_availability&oldid=933004783\"\n\t\t\n\t\tCategories: System administrationQuality controlApplied probabilityReliability engineeringMeasurementHidden categories: Use American English from March 2019All Wikipedia articles written in American EnglishArticles with short descriptionUse mdy dates from March 2019Articles needing additional references from June 2008All articles needing additional referencesAll articles with unsourced statementsArticles with unsourced statements from August 2008\n\t\t\n\t\t\n\t"},
{"URL": "https://en.wikipedia.org/wiki/FreeNATS", "webContent": "\n\t\tFrom Wikipedia, the free encyclopedia\n\t\t\n\t\t\n\t\t\n\t\t\n\t\t\n\t\tJump to navigation\n\t\tJump to search\n\t\tFreeNATSOriginal author(s)David CuttingDeveloper(s)PurplePixie SystemsInitial releaseMarch\u00a02,\u00a02008\u00a0(2008-03-02)[1]Stable release1.20.1b\n   / November\u00a014, 2018; 13 months ago\u00a0(2018-11-14)[2]\nOperating systemUnix-likePlatformPHP / MySQLAvailable inEnglishTypeNetwork monitoringLicenseGNU General Public LicenseWebsitewww.purplepixie.org/freenats/\nFreeNATS (the Free Network Automatic Testing System) is an open-source network monitoring software application[3] developed by David Cutting under the banner of PurplePixie Systems.\nFreeNATS is free software licensed under the terms of the GNU General Public License version 3 as published by the Free Software Foundation.\n\nContents\n\n1 Overview\n2 See also\n3 References\n4 External links\n\n\n\nOverview[edit]\nMonitoring of network services (SMTP, POP3, HTTP, ICMP (ping)[4]\nLimited monitoring of host resources (processor load, disk usage) on a majority of network operating systems, including Microsoft Windows and Linux through agent-based testing\nPlugin design that allows users to easily develop their own service checks depending on needs, by using PHP (or other languages or scripts wrapped in PHP)\nSome ability to define network host hierarchy using \"master\" nodes allowing link failures to suspend monitoring[5]\nEvent-based system allowing failure notifications to be sent in customised email (suitable for email-to-SMS) or to utilise third-party notification scripts via a plug-in\nAbility to define event handlers to be run during service or host events for proactive problem resolution\nAutomatic data retention cleanups\nFull web-interface for management and monitoring\nAbility to \"publish\" views and graphs within third-party web pages\nSee also[edit]\nComparison of network monitoring systems\nReferences[edit]\n\n\n^ first release referenced in http://www.purplepixie.org/freenats/news.php?id=91\n\n^ FreeNATS Release Download\n\n^ NetworkWorld.com Article on FreeNATS\n\n^ PC Quest Article Archived 2009-02-10 at the Wayback Machine on FreeNATS\n\n^ Master Node Documentation on FreeNATS Wiki\n\n\nExternal links[edit]\npurplepixie.org/freenats, official website\nFreeNATS Wiki\nSupport Forum for FreeNATS\nNetworkWorld.com Article on FreeNATS\nPC Quest Article on FreeNATS\n\n\n\n\n\n\t\t\n\t\tRetrieved from \"https://en.wikipedia.org/w/index.php?title=FreeNATS&oldid=931812881\"\n\t\t\n\t\tCategories: Network managementInternet Protocol based network softwareFree network management softwareHidden categories: Webarchive template wayback links\n\t\t\n\t\t\n\t"}
]